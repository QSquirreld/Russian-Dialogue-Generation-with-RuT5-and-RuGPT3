# Russian Dialogue Generation with RuT5 and RuGPT3

Решение задачи **диалогового моделирования** с применением encoder-decoder и decoder-only моделей.

Модели дообучены на основе диалогов из датасета [`zjkarina/matreshka`](https://huggingface.co/datasets/zjkarina/matreshka).

## Цель проекта

Сравнить архитектуры encoder-decoder и decoder-only в задаче диалогового моделирования.

## Задачи

1. Проверить работу модели в сценарии близком к выбранному датасету в zero-shot режиме.
2. Посчитать метрики BLEU и METEOR исходной модели на валидационном сабсете выбранного датасета.
3. Дообучить модель на обучающем сабсете выбранного датасета.
4. Проверить работу модели в сценарии близком к выбранному датасету.
5. Посчитать метрики BLEU и METEOR обученной модели на валидационном сабсете выбранного датасета.

## Модели

- encoder-decoder — RuT5 — [`cointegrated/rut5-small-chitchat2`](https://huggingface.co/cointegrated/rut5-small-chitchat2)
  - Модель семейства T5, дообученная для генерации диалогов на русском языке.
- decoder only — RuGPT3 — [`ai-forever/rugpt3small_based_on_gpt2`](https://huggingface.co/ai-forever/rugpt3small_based_on_gpt2)
  - Компактная версия GPT2, ориентированная на генерацию текста на русском языке.

## Датасет

- [`zjkarina/matreshka`](https://huggingface.co/datasets/zjkarina/matreshka) — корпус русскоязычных диалогов.
- Язык: `русский`
- Количество диалогов: `8 319`
- Диалоги в формате:
  - `role = ['user', 'bot']` — роли,
  - `dialog = ['Привет', 'Привет! Как дела?']` — реплики
  - `persona` — описание(состояние) пользователя (не исп. в задаче)
  - `summary` — самари диалога (не исп. в задаче)

## Метрики
- `BLEU` (Bilingual Evaluation Understudy)<br>— n-граммная метрика, измеряет точность совпадений между предсказанием и эталоном.
    - Подходит для кратких ответов
    - Не учитывает перефразирование и синонимы
- `METEOR` (Metric for Evaluation of Translation with Explicit ORdering)
    - для оценки смыслового соответствия
    - учитывает порядок слов, леммы, синонимы, перефразирование

## Структура ноутбуков

1. Zero-Shot тестирование генерации ответов

2. Загрузка и препроцессинг данных
- Вспомогательными функциями `_df_to_t5_format`/``_df_to_gpt_format``, `_shrink_roles_and_dialogue` и `_drop_first_bot_last_user_utterings`:<br>Диалоги преведены к виду `user` → `bot`, также убраны разрывы
   
3. Токенизация (см. "Модификации")
- Для encoder-decoder:
  - Отдельно токенизируются `source_text` и `target_text` с помощью `T5Tokenizer`
- Для decoder-only:
  - Токенизируется весь текст диалога (включая `<user>` и `<bot>`)
  - Дополнительно формируются `labels`, совпадающие с `input_ids` (кроме токенов padding)
   
4. Fine-Tuning

5. Генерация ответов дообученной модели

5. Оценка ответов модели метриками `BLEU` и `METEOR`
- *до и после дообучения*

## Модификации

В проекте учтены различия между архитектурами моделей:<br>
Encoder-Decoder (RuT5):
1. Данные приведены к формату source_text → target_text
2. Добавлен префикс `ответь`: к source_text для уточнения задачи
3. Токенизация производится отдельно для входа и выхода

Decoder-Only (RuGPT3):
1. Токенизатор дополнен специальными токенами: `<user>` и `<bot>`
2. Диалоги объединены в единый текст с разметкой ролей (`<user>` и `<bot>`)
    - имеют вид: `<user>USERTEXT<bot>BOTTEXT</s>`

## Полученные метрики

|Модель|Метрика|Значение (initial)|Значение (fine-tuned)|
|------|-------|------------------|---------------------|
|RuT5|BLEU|0.093|0.147|
|RuT5|METEOR|0.045|0.152|
|RuGPT3|BLEU|0.097|0.097|
|RuGPT3|METEOR|0.146|0.146|

## Выводы

1. "Из коробки" `gpt3small` показывает себя лучше `RuT5`, что может говорить о лучшем предобучении или лучшем базовом качестве для диалоговых задач.
2. После fine-tuning `RuT5` показала лучший результат.
- *Должно быть наоборот по идеи..*
3. Метрики `gpt3small` никак не изменились, однако сам ответ стал качественней.
- Как и ожидалось модель продолжает диалог, а не просто отвечает на вопрос. В отличие от `RuT5` которая отвечает коротко и ёмко.
4. Метрики `RuT5` подросли
- `METEOR` вырос относительно значительно
5. Говоря в общем метрики всё равно слабые.
6. **Возможные причины и решения описаны внутри ноутбуков**

## Результат

Модель успешно генерирует релевантные ответы, особенно на короткие приветственные или бытовые реплики. Можно использовать как базу для дообучения под более специфичные задачи (техподдержка, медицина и т.д.).

## Возможные доработки

- Fine-tuning на дополнительном домене (медицина, банки)
- Обучать модель дольше и тщательнее (т.к. Google Colab даёт ограниченные ресурсы и время)
- Использование более крупной модели (например, `rut5-base` или `rugpt3medium`) для повышения качества генерации
- Внедрение персонификации с учётом поля persona из датасета
- Поддержка мульти-turn диалога
- Поддержка различных сценариев общения (FAQ, small talk, интервью и т.д.)

## Как запустить
1. Установить библиотеки
```bash
pip install transformers, datasets, torch, pandas, tqdm, sklearn, torchmetrics, re, evaluate
```

2. Запустить нужный ноутбук
- Через `jupyter`:<br>
```bash
pip install jupyter
jupyter notebook
```
- Через `Google Colab`: просто запустить нужный notebook

    Открыть нужный notebook: `Dialogue_Generator_RUT5.ipynb` или `Dialogue_Generator_RUGPT3.ipynb`
3. Аппаратные требования
- Рекомендуется GPU (например, Google Colab с `T4/V100/A100`)
- Объём памяти: от `12 ГБ` и выше для комфортного обучения